{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import math \n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos preentrenados, visualizando con las utilidades de ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del modelo\n",
    "#model = YOLO('yolo11n.pt') #Contenedores\n",
    "#model = YOLO('yolo11n-seg.pt') #Máscaras\n",
    "model = YOLO('yolo11n-pose.pt')  #Pose\n",
    "\n",
    "#Para un vídeo \n",
    "filename = \"TGC23_PdH_C0056cut.mp4\"\n",
    "results = model(filename, show=True)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde cámara, detección con yolo11, modelo nano. Visualización propia con OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del modelo, descarga en disco si no está presente en la carpeta\n",
    "model = YOLO('yolo11n.pt') #Contenedores\n",
    "\n",
    "# Etiqueta de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "\n",
    "# Captura desde la webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # si hay imagen válida\n",
    "    if ret:  \n",
    "        # Detecta en la imagen\n",
    "        results = model(img, stream=True)\n",
    "        \n",
    "        # Para cada detección\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confianza --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Clase -->\", classNames[cls])\n",
    "\n",
    "                # Convierte identificador numérico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255*2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255*2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                # Dibuja el contenedor y clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', img)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguimiento. Requiere instalar lap con pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 46.0ms\n",
      "Speed: 2.5ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 87, 105,  93],\n",
      "        [ 83, 101,  89],\n",
      "        [ 83, 101,  89],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 81,  99,  87],\n",
      "        [ 95, 113, 101],\n",
      "        [104, 122, 110],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 64,  84,  72],\n",
      "        [ 82, 102,  90],\n",
      "        [ 95, 115, 103],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 27,  38,  39],\n",
      "        [ 27,  38,  39],\n",
      "        [ 25,  36,  37],\n",
      "        ...,\n",
      "        [ 62,  66,  68],\n",
      "        [ 55,  59,  61],\n",
      "        [ 48,  52,  54]],\n",
      "\n",
      "       [[ 23,  34,  35],\n",
      "        [ 26,  37,  38],\n",
      "        [ 26,  37,  38],\n",
      "        ...,\n",
      "        [ 49,  53,  55],\n",
      "        [ 46,  50,  52],\n",
      "        [ 42,  46,  48]],\n",
      "\n",
      "       [[ 20,  31,  32],\n",
      "        [ 25,  36,  37],\n",
      "        [ 27,  38,  39],\n",
      "        ...,\n",
      "        [ 29,  33,  35],\n",
      "        [ 34,  38,  40],\n",
      "        [ 40,  44,  46]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 2.50244140625, 'inference': 46.03981971740723, 'postprocess': 1.0004043579101562}\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 46.5ms\n",
      "Speed: 1.5ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 93, 108,  97],\n",
      "        [ 79,  94,  83],\n",
      "        [ 84, 102,  90],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 84,  99,  88],\n",
      "        [101, 116, 105],\n",
      "        [110, 128, 116],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 66,  84,  72],\n",
      "        [ 84, 102,  90],\n",
      "        [ 95, 113, 101],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 28,  39,  40],\n",
      "        [ 25,  36,  37],\n",
      "        [ 22,  33,  34],\n",
      "        ...,\n",
      "        [ 61,  65,  67],\n",
      "        [ 53,  57,  59],\n",
      "        [ 41,  45,  47]],\n",
      "\n",
      "       [[ 27,  38,  39],\n",
      "        [ 27,  38,  39],\n",
      "        [ 26,  37,  38],\n",
      "        ...,\n",
      "        [ 52,  56,  58],\n",
      "        [ 46,  50,  52],\n",
      "        [ 34,  38,  40]],\n",
      "\n",
      "       [[ 26,  37,  38],\n",
      "        [ 28,  39,  40],\n",
      "        [ 30,  41,  42],\n",
      "        ...,\n",
      "        [ 38,  42,  44],\n",
      "        [ 41,  45,  47],\n",
      "        [ 35,  39,  41]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.5015602111816406, 'inference': 46.54359817504883, 'postprocess': 0.9970664978027344}\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 40.0ms\n",
      "Speed: 1.5ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 93, 108,  97],\n",
      "        [ 79,  94,  83],\n",
      "        [ 84, 102,  90],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 84,  99,  88],\n",
      "        [101, 116, 105],\n",
      "        [110, 128, 116],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 66,  84,  72],\n",
      "        [ 84, 102,  90],\n",
      "        [ 95, 113, 101],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 32,  39,  40],\n",
      "        [ 29,  36,  37],\n",
      "        [ 24,  33,  34],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 53,  57,  59],\n",
      "        [ 42,  46,  48]],\n",
      "\n",
      "       [[ 31,  38,  39],\n",
      "        [ 31,  38,  39],\n",
      "        [ 28,  37,  38],\n",
      "        ...,\n",
      "        [ 53,  57,  59],\n",
      "        [ 46,  50,  52],\n",
      "        [ 33,  37,  39]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 32,  39,  40],\n",
      "        [ 32,  41,  42],\n",
      "        ...,\n",
      "        [ 40,  44,  46],\n",
      "        [ 41,  45,  47],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.5027523040771484, 'inference': 40.035247802734375, 'postprocess': 0.9987354278564453}\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 44.5ms\n",
      "Speed: 1.5ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 93, 108,  97],\n",
      "        [ 79,  94,  83],\n",
      "        [ 84, 102,  90],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 84,  99,  88],\n",
      "        [101, 116, 105],\n",
      "        [110, 128, 116],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 66,  84,  72],\n",
      "        [ 84, 102,  90],\n",
      "        [ 95, 113, 101],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 32,  39,  40],\n",
      "        [ 29,  36,  37],\n",
      "        [ 24,  33,  34],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 53,  57,  59],\n",
      "        [ 42,  46,  48]],\n",
      "\n",
      "       [[ 31,  38,  39],\n",
      "        [ 31,  38,  39],\n",
      "        [ 28,  37,  38],\n",
      "        ...,\n",
      "        [ 53,  57,  59],\n",
      "        [ 46,  50,  52],\n",
      "        [ 33,  37,  39]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 32,  39,  40],\n",
      "        [ 32,  41,  42],\n",
      "        ...,\n",
      "        [ 40,  44,  46],\n",
      "        [ 41,  45,  47],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.505136489868164, 'inference': 44.53420639038086, 'postprocess': 1.001119613647461}\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 41.5ms\n",
      "Speed: 1.5ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 93, 108,  97],\n",
      "        [ 79,  94,  83],\n",
      "        [ 84, 102,  90],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 84,  99,  88],\n",
      "        [101, 116, 105],\n",
      "        [110, 128, 116],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 66,  84,  72],\n",
      "        [ 84, 102,  90],\n",
      "        [ 95, 113, 101],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 32,  39,  40],\n",
      "        [ 29,  36,  37],\n",
      "        [ 24,  33,  34],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 53,  57,  59],\n",
      "        [ 42,  46,  48]],\n",
      "\n",
      "       [[ 31,  38,  39],\n",
      "        [ 31,  38,  39],\n",
      "        [ 28,  37,  38],\n",
      "        ...,\n",
      "        [ 53,  57,  59],\n",
      "        [ 46,  50,  52],\n",
      "        [ 33,  37,  39]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 32,  39,  40],\n",
      "        [ 32,  41,  42],\n",
      "        ...,\n",
      "        [ 40,  44,  46],\n",
      "        [ 41,  45,  47],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.5017986297607422, 'inference': 41.53943061828613, 'postprocess': 0.49591064453125}\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 93, 108,  97],\n",
      "        [ 79,  94,  83],\n",
      "        [ 84, 102,  90],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 84,  99,  88],\n",
      "        [101, 116, 105],\n",
      "        [110, 128, 116],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 66,  84,  72],\n",
      "        [ 84, 102,  90],\n",
      "        [ 95, 113, 101],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 32,  39,  40],\n",
      "        [ 29,  36,  37],\n",
      "        [ 24,  33,  34],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 53,  57,  59],\n",
      "        [ 42,  46,  48]],\n",
      "\n",
      "       [[ 31,  38,  39],\n",
      "        [ 31,  38,  39],\n",
      "        [ 28,  37,  38],\n",
      "        ...,\n",
      "        [ 53,  57,  59],\n",
      "        [ 46,  50,  52],\n",
      "        [ 33,  37,  39]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 32,  39,  40],\n",
      "        [ 32,  41,  42],\n",
      "        ...,\n",
      "        [ 40,  44,  46],\n",
      "        [ 41,  45,  47],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.0008811950683594, 'inference': 42.035818099975586, 'postprocess': 1.001119613647461}\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 39.0ms\n",
      "Speed: 1.5ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 93, 108,  97],\n",
      "        [ 79,  94,  83],\n",
      "        [ 84, 102,  90],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 84,  99,  88],\n",
      "        [101, 116, 105],\n",
      "        [110, 128, 116],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 66,  84,  72],\n",
      "        [ 84, 102,  90],\n",
      "        [ 95, 113, 101],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 33,  40,  41],\n",
      "        [ 30,  37,  38],\n",
      "        [ 24,  33,  34],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 53,  57,  59],\n",
      "        [ 42,  46,  48]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 30,  37,  38],\n",
      "        [ 28,  37,  38],\n",
      "        ...,\n",
      "        [ 53,  57,  59],\n",
      "        [ 46,  50,  52],\n",
      "        [ 33,  37,  39]],\n",
      "\n",
      "       [[ 27,  34,  35],\n",
      "        [ 30,  37,  38],\n",
      "        [ 31,  40,  41],\n",
      "        ...,\n",
      "        [ 40,  44,  46],\n",
      "        [ 41,  45,  47],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.501321792602539, 'inference': 39.03341293334961, 'postprocess': 1.0013580322265625}\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 39.5ms\n",
      "Speed: 1.5ms preprocess, 39.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 93, 108,  97],\n",
      "        [ 79,  94,  83],\n",
      "        [ 84, 102,  90],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 84,  99,  88],\n",
      "        [101, 116, 105],\n",
      "        [110, 128, 116],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 66,  84,  72],\n",
      "        [ 84, 102,  90],\n",
      "        [ 95, 113, 101],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 33,  40,  41],\n",
      "        [ 30,  37,  38],\n",
      "        [ 24,  33,  34],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 53,  57,  59],\n",
      "        [ 42,  46,  48]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 30,  37,  38],\n",
      "        [ 28,  37,  38],\n",
      "        ...,\n",
      "        [ 53,  57,  59],\n",
      "        [ 46,  50,  52],\n",
      "        [ 33,  37,  39]],\n",
      "\n",
      "       [[ 27,  34,  35],\n",
      "        [ 30,  37,  38],\n",
      "        [ 31,  40,  41],\n",
      "        ...,\n",
      "        [ 40,  44,  46],\n",
      "        [ 41,  45,  47],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.5039443969726562, 'inference': 39.53194618225098, 'postprocess': 1.0006427764892578}\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 41.0ms\n",
      "Speed: 1.5ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 93, 108,  97],\n",
      "        [ 79,  94,  83],\n",
      "        [ 84, 102,  90],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 84,  99,  88],\n",
      "        [101, 116, 105],\n",
      "        [110, 128, 116],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 66,  84,  72],\n",
      "        [ 84, 102,  90],\n",
      "        [ 95, 113, 101],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 33,  40,  41],\n",
      "        [ 30,  37,  38],\n",
      "        [ 24,  33,  34],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 53,  57,  59],\n",
      "        [ 42,  46,  48]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 30,  37,  38],\n",
      "        [ 28,  37,  38],\n",
      "        ...,\n",
      "        [ 53,  57,  59],\n",
      "        [ 46,  50,  52],\n",
      "        [ 33,  37,  39]],\n",
      "\n",
      "       [[ 27,  34,  35],\n",
      "        [ 30,  37,  38],\n",
      "        [ 31,  40,  41],\n",
      "        ...,\n",
      "        [ 40,  44,  46],\n",
      "        [ 41,  45,  47],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.5020370483398438, 'inference': 41.034698486328125, 'postprocess': 1.001119613647461}\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 93, 108,  97],\n",
      "        [ 79,  94,  83],\n",
      "        [ 84, 102,  90],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 84,  99,  88],\n",
      "        [101, 116, 105],\n",
      "        [110, 128, 116],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 66,  84,  72],\n",
      "        [ 84, 102,  90],\n",
      "        [ 95, 113, 101],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 33,  40,  41],\n",
      "        [ 30,  37,  38],\n",
      "        [ 24,  33,  34],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 53,  57,  59],\n",
      "        [ 42,  46,  48]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 30,  37,  38],\n",
      "        [ 28,  37,  38],\n",
      "        ...,\n",
      "        [ 53,  57,  59],\n",
      "        [ 46,  50,  52],\n",
      "        [ 33,  37,  39]],\n",
      "\n",
      "       [[ 27,  34,  35],\n",
      "        [ 30,  37,  38],\n",
      "        [ 31,  40,  41],\n",
      "        ...,\n",
      "        [ 40,  44,  46],\n",
      "        [ 41,  45,  47],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.0008811950683594, 'inference': 42.03677177429199, 'postprocess': 1.0001659393310547}\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 5 persons, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 93, 108,  97],\n",
      "        [ 79,  94,  83],\n",
      "        [ 84, 102,  90],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 84,  99,  88],\n",
      "        [101, 116, 105],\n",
      "        [110, 128, 116],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 66,  84,  72],\n",
      "        [ 84, 102,  90],\n",
      "        [ 95, 113, 101],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 33,  40,  41],\n",
      "        [ 30,  37,  38],\n",
      "        [ 24,  33,  34],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 53,  57,  59],\n",
      "        [ 42,  46,  48]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 30,  37,  38],\n",
      "        [ 28,  37,  38],\n",
      "        ...,\n",
      "        [ 53,  57,  59],\n",
      "        [ 46,  50,  52],\n",
      "        [ 33,  37,  39]],\n",
      "\n",
      "       [[ 27,  34,  35],\n",
      "        [ 30,  37,  38],\n",
      "        [ 31,  40,  41],\n",
      "        ...,\n",
      "        [ 40,  44,  46],\n",
      "        [ 41,  45,  47],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.0006427764892578, 'inference': 44.04139518737793, 'postprocess': 0.9973049163818359}\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 5 persons, 40.5ms\n",
      "Speed: 1.5ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 93, 108,  97],\n",
      "        [ 79,  94,  83],\n",
      "        [ 84, 102,  90],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 84,  99,  88],\n",
      "        [101, 116, 105],\n",
      "        [110, 128, 116],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 66,  84,  72],\n",
      "        [ 84, 102,  90],\n",
      "        [ 95, 113, 101],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 33,  40,  41],\n",
      "        [ 30,  37,  38],\n",
      "        [ 24,  33,  34],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 53,  57,  59],\n",
      "        [ 42,  46,  48]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 30,  37,  38],\n",
      "        [ 28,  37,  38],\n",
      "        ...,\n",
      "        [ 53,  57,  59],\n",
      "        [ 46,  50,  52],\n",
      "        [ 33,  37,  39]],\n",
      "\n",
      "       [[ 27,  34,  35],\n",
      "        [ 30,  37,  38],\n",
      "        [ 31,  40,  41],\n",
      "        ...,\n",
      "        [ 40,  44,  46],\n",
      "        [ 41,  45,  47],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.501321792602539, 'inference': 40.53497314453125, 'postprocess': 0.5002021789550781}\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 88, 108,  96],\n",
      "        [ 79,  99,  87],\n",
      "        [ 92, 105,  94],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 80, 100,  88],\n",
      "        [103, 123, 111],\n",
      "        [121, 134, 123],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 61,  79,  67],\n",
      "        [ 83, 101,  89],\n",
      "        [101, 112, 101],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 32,  39,  40],\n",
      "        [ 30,  37,  38],\n",
      "        [ 27,  36,  37],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 54,  58,  60],\n",
      "        [ 40,  44,  46]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 30,  37,  38],\n",
      "        [ 29,  38,  39],\n",
      "        ...,\n",
      "        [ 55,  59,  61],\n",
      "        [ 48,  52,  54],\n",
      "        [ 36,  40,  42]],\n",
      "\n",
      "       [[ 29,  36,  37],\n",
      "        [ 31,  38,  39],\n",
      "        [ 31,  40,  41],\n",
      "        ...,\n",
      "        [ 41,  45,  47],\n",
      "        [ 40,  44,  46],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.0013580322265625, 'inference': 40.03429412841797, 'postprocess': 0.5002021789550781}\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 90, 110,  98],\n",
      "        [ 81, 101,  89],\n",
      "        [ 93, 106,  95],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 80, 100,  88],\n",
      "        [103, 123, 111],\n",
      "        [121, 134, 123],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 59,  77,  65],\n",
      "        [ 81,  99,  87],\n",
      "        [100, 111, 100],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 32,  39,  40],\n",
      "        [ 30,  37,  38],\n",
      "        [ 27,  36,  37],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 54,  58,  60],\n",
      "        [ 40,  44,  46]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 30,  37,  38],\n",
      "        [ 29,  38,  39],\n",
      "        ...,\n",
      "        [ 55,  59,  61],\n",
      "        [ 48,  52,  54],\n",
      "        [ 36,  40,  42]],\n",
      "\n",
      "       [[ 29,  36,  37],\n",
      "        [ 31,  38,  39],\n",
      "        [ 31,  40,  41],\n",
      "        ...,\n",
      "        [ 41,  45,  47],\n",
      "        [ 40,  44,  46],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.0020732879638672, 'inference': 39.0324592590332, 'postprocess': 0.5004405975341797}\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 90, 110,  98],\n",
      "        [ 81, 101,  89],\n",
      "        [ 93, 106,  95],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 80, 100,  88],\n",
      "        [103, 123, 111],\n",
      "        [121, 134, 123],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 59,  77,  65],\n",
      "        [ 81,  99,  87],\n",
      "        [100, 111, 100],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 32,  39,  40],\n",
      "        [ 30,  37,  38],\n",
      "        [ 27,  36,  37],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 54,  58,  60],\n",
      "        [ 40,  44,  46]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 30,  37,  38],\n",
      "        [ 29,  38,  39],\n",
      "        ...,\n",
      "        [ 55,  59,  61],\n",
      "        [ 48,  52,  54],\n",
      "        [ 36,  40,  42]],\n",
      "\n",
      "       [[ 29,  36,  37],\n",
      "        [ 31,  38,  39],\n",
      "        [ 31,  40,  41],\n",
      "        ...,\n",
      "        [ 41,  45,  47],\n",
      "        [ 40,  44,  46],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.0004043579101562, 'inference': 38.538217544555664, 'postprocess': 0.4954338073730469}\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 90, 110,  98],\n",
      "        [ 81, 101,  89],\n",
      "        [ 94, 107,  96],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 80, 100,  88],\n",
      "        [102, 122, 110],\n",
      "        [119, 132, 121],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 59,  77,  65],\n",
      "        [ 82, 100,  88],\n",
      "        [102, 113, 102],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 32,  39,  40],\n",
      "        [ 30,  37,  38],\n",
      "        [ 27,  36,  37],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 54,  58,  60],\n",
      "        [ 40,  44,  46]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 30,  37,  38],\n",
      "        [ 29,  38,  39],\n",
      "        ...,\n",
      "        [ 55,  59,  61],\n",
      "        [ 48,  52,  54],\n",
      "        [ 36,  40,  42]],\n",
      "\n",
      "       [[ 29,  36,  37],\n",
      "        [ 31,  38,  39],\n",
      "        [ 31,  40,  41],\n",
      "        ...,\n",
      "        [ 41,  45,  47],\n",
      "        [ 40,  44,  46],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.0008811950683594, 'inference': 39.03388977050781, 'postprocess': 1.0001659393310547}\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.5ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 90, 110,  98],\n",
      "        [ 81, 101,  89],\n",
      "        [ 94, 107,  96],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 80, 100,  88],\n",
      "        [102, 122, 110],\n",
      "        [119, 132, 121],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 59,  77,  65],\n",
      "        [ 82, 100,  88],\n",
      "        [102, 113, 102],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 32,  39,  40],\n",
      "        [ 30,  37,  38],\n",
      "        [ 27,  36,  37],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 54,  58,  60],\n",
      "        [ 40,  44,  46]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 30,  37,  38],\n",
      "        [ 29,  38,  39],\n",
      "        ...,\n",
      "        [ 55,  59,  61],\n",
      "        [ 48,  52,  54],\n",
      "        [ 36,  40,  42]],\n",
      "\n",
      "       [[ 29,  36,  37],\n",
      "        [ 31,  38,  39],\n",
      "        [ 31,  40,  41],\n",
      "        ...,\n",
      "        [ 41,  45,  47],\n",
      "        [ 40,  44,  46],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.501321792602539, 'inference': 39.04318809509277, 'postprocess': 0.4913806915283203}\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.5ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 90, 110,  98],\n",
      "        [ 81, 101,  89],\n",
      "        [ 94, 107,  96],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 80, 100,  88],\n",
      "        [102, 122, 110],\n",
      "        [119, 132, 121],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 59,  77,  65],\n",
      "        [ 82, 100,  88],\n",
      "        [102, 113, 102],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 32,  39,  40],\n",
      "        [ 30,  37,  38],\n",
      "        [ 27,  36,  37],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 54,  58,  60],\n",
      "        [ 40,  44,  46]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 30,  37,  38],\n",
      "        [ 29,  38,  39],\n",
      "        ...,\n",
      "        [ 55,  59,  61],\n",
      "        [ 48,  52,  54],\n",
      "        [ 36,  40,  42]],\n",
      "\n",
      "       [[ 29,  36,  37],\n",
      "        [ 31,  38,  39],\n",
      "        [ 31,  40,  41],\n",
      "        ...,\n",
      "        [ 41,  45,  47],\n",
      "        [ 40,  44,  46],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.5017986297607422, 'inference': 39.03317451477051, 'postprocess': 1.0004043579101562}\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 90, 110,  98],\n",
      "        [ 81, 101,  89],\n",
      "        [ 94, 107,  96],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 80, 100,  88],\n",
      "        [102, 122, 110],\n",
      "        [119, 132, 121],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 59,  77,  65],\n",
      "        [ 82, 100,  88],\n",
      "        [102, 113, 102],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 32,  39,  40],\n",
      "        [ 30,  37,  38],\n",
      "        [ 27,  36,  37],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 54,  58,  60],\n",
      "        [ 40,  44,  46]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 30,  37,  38],\n",
      "        [ 29,  38,  39],\n",
      "        ...,\n",
      "        [ 55,  59,  61],\n",
      "        [ 48,  52,  54],\n",
      "        [ 36,  40,  42]],\n",
      "\n",
      "       [[ 29,  36,  37],\n",
      "        [ 31,  38,  39],\n",
      "        [ 31,  40,  41],\n",
      "        ...,\n",
      "        [ 41,  45,  47],\n",
      "        [ 40,  44,  46],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.0008811950683594, 'inference': 39.03388977050781, 'postprocess': 1.0004043579101562}\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 90, 110,  98],\n",
      "        [ 81, 101,  89],\n",
      "        [ 94, 107,  96],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 80, 100,  88],\n",
      "        [102, 122, 110],\n",
      "        [119, 132, 121],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 59,  77,  65],\n",
      "        [ 82, 100,  88],\n",
      "        [102, 113, 102],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 32,  39,  40],\n",
      "        [ 30,  37,  38],\n",
      "        [ 27,  36,  37],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 54,  58,  60],\n",
      "        [ 40,  44,  46]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 30,  37,  38],\n",
      "        [ 29,  38,  39],\n",
      "        ...,\n",
      "        [ 55,  59,  61],\n",
      "        [ 48,  52,  54],\n",
      "        [ 36,  40,  42]],\n",
      "\n",
      "       [[ 29,  36,  37],\n",
      "        [ 31,  38,  39],\n",
      "        [ 31,  40,  41],\n",
      "        ...,\n",
      "        [ 41,  45,  47],\n",
      "        [ 40,  44,  46],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.001119613647461, 'inference': 39.54291343688965, 'postprocess': 0.9918212890625}\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 90, 110,  98],\n",
      "        [ 81, 101,  89],\n",
      "        [ 94, 107,  96],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 80, 100,  88],\n",
      "        [102, 122, 110],\n",
      "        [119, 132, 121],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 59,  77,  65],\n",
      "        [ 82, 100,  88],\n",
      "        [102, 113, 102],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 32,  39,  40],\n",
      "        [ 30,  37,  38],\n",
      "        [ 27,  36,  37],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 54,  58,  60],\n",
      "        [ 40,  44,  46]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 30,  37,  38],\n",
      "        [ 29,  38,  39],\n",
      "        ...,\n",
      "        [ 55,  59,  61],\n",
      "        [ 48,  52,  54],\n",
      "        [ 36,  40,  42]],\n",
      "\n",
      "       [[ 29,  36,  37],\n",
      "        [ 31,  38,  39],\n",
      "        [ 31,  40,  41],\n",
      "        ...,\n",
      "        [ 41,  45,  47],\n",
      "        [ 40,  44,  46],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.001596450805664, 'inference': 39.03651237487793, 'postprocess': 0.4982948303222656}\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 90, 110,  98],\n",
      "        [ 81, 101,  89],\n",
      "        [ 94, 107,  96],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 80, 100,  88],\n",
      "        [102, 122, 110],\n",
      "        [119, 132, 121],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 59,  77,  65],\n",
      "        [ 82, 100,  88],\n",
      "        [102, 113, 102],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 32,  39,  40],\n",
      "        [ 30,  37,  38],\n",
      "        [ 27,  36,  37],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 54,  58,  60],\n",
      "        [ 40,  44,  46]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 30,  37,  38],\n",
      "        [ 29,  38,  39],\n",
      "        ...,\n",
      "        [ 55,  59,  61],\n",
      "        [ 48,  52,  54],\n",
      "        [ 36,  40,  42]],\n",
      "\n",
      "       [[ 29,  36,  37],\n",
      "        [ 31,  38,  39],\n",
      "        [ 31,  40,  41],\n",
      "        ...,\n",
      "        [ 41,  45,  47],\n",
      "        [ 40,  44,  46],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.0449886322021484, 'inference': 39.48974609375, 'postprocess': 0.5004405975341797}\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.5ms\n",
      "Speed: 1.5ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 90, 110,  98],\n",
      "        [ 81, 101,  89],\n",
      "        [ 94, 107,  96],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 80, 100,  88],\n",
      "        [102, 122, 110],\n",
      "        [119, 132, 121],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 59,  77,  65],\n",
      "        [ 82, 100,  88],\n",
      "        [102, 113, 102],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 32,  39,  40],\n",
      "        [ 30,  37,  38],\n",
      "        [ 27,  36,  37],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 54,  58,  60],\n",
      "        [ 40,  44,  46]],\n",
      "\n",
      "       [[ 30,  37,  38],\n",
      "        [ 30,  37,  38],\n",
      "        [ 29,  38,  39],\n",
      "        ...,\n",
      "        [ 55,  59,  61],\n",
      "        [ 48,  52,  54],\n",
      "        [ 36,  40,  42]],\n",
      "\n",
      "       [[ 29,  36,  37],\n",
      "        [ 31,  38,  39],\n",
      "        [ 31,  40,  41],\n",
      "        ...,\n",
      "        [ 41,  45,  47],\n",
      "        [ 40,  44,  46],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.5025138854980469, 'inference': 39.537668228149414, 'postprocess': 0.49567222595214844}\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 90, 110,  98],\n",
      "        [ 81, 101,  89],\n",
      "        [ 94, 107,  96],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 80, 100,  88],\n",
      "        [102, 122, 110],\n",
      "        [119, 132, 121],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 59,  77,  65],\n",
      "        [ 82, 100,  88],\n",
      "        [102, 113, 102],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 33,  40,  41],\n",
      "        [ 30,  37,  38],\n",
      "        [ 27,  36,  37],\n",
      "        ...,\n",
      "        [ 60,  64,  66],\n",
      "        [ 54,  58,  60],\n",
      "        [ 40,  44,  46]],\n",
      "\n",
      "       [[ 29,  36,  37],\n",
      "        [ 30,  37,  38],\n",
      "        [ 29,  38,  39],\n",
      "        ...,\n",
      "        [ 55,  59,  61],\n",
      "        [ 48,  52,  54],\n",
      "        [ 36,  40,  42]],\n",
      "\n",
      "       [[ 26,  33,  34],\n",
      "        [ 30,  37,  38],\n",
      "        [ 32,  41,  42],\n",
      "        ...,\n",
      "        [ 41,  45,  47],\n",
      "        [ 40,  44,  46],\n",
      "        [ 33,  37,  39]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.0008811950683594, 'inference': 40.53497314453125, 'postprocess': 1.0006427764892578}\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 78, 108,  94],\n",
      "        [ 71, 101,  87],\n",
      "        [ 86, 113, 100],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 71, 101,  87],\n",
      "        [ 93, 123, 109],\n",
      "        [103, 130, 117],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 48,  73,  60],\n",
      "        [ 77, 102,  89],\n",
      "        [ 94, 114, 102],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 28,  39,  40],\n",
      "        [ 26,  37,  38],\n",
      "        [ 23,  34,  35],\n",
      "        ...,\n",
      "        [ 61,  64,  69],\n",
      "        [ 55,  58,  63],\n",
      "        [ 41,  44,  49]],\n",
      "\n",
      "       [[ 25,  36,  37],\n",
      "        [ 26,  37,  38],\n",
      "        [ 27,  38,  39],\n",
      "        ...,\n",
      "        [ 54,  57,  62],\n",
      "        [ 52,  55,  60],\n",
      "        [ 35,  38,  43]],\n",
      "\n",
      "       [[ 23,  34,  35],\n",
      "        [ 26,  37,  38],\n",
      "        [ 29,  40,  41],\n",
      "        ...,\n",
      "        [ 39,  42,  47],\n",
      "        [ 43,  46,  51],\n",
      "        [ 29,  32,  37]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.0013580322265625, 'inference': 39.03317451477051, 'postprocess': 1.0006427764892578}\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.5ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 84, 114, 100],\n",
      "        [ 71, 101,  87],\n",
      "        [ 82, 109,  96],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 70, 100,  86],\n",
      "        [ 96, 126, 112],\n",
      "        [107, 134, 121],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 53,  78,  65],\n",
      "        [ 76, 101,  88],\n",
      "        [ 92, 112, 100],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 28,  39,  40],\n",
      "        [ 26,  37,  38],\n",
      "        [ 23,  34,  35],\n",
      "        ...,\n",
      "        [ 61,  65,  67],\n",
      "        [ 55,  59,  61],\n",
      "        [ 41,  45,  47]],\n",
      "\n",
      "       [[ 25,  36,  37],\n",
      "        [ 26,  37,  38],\n",
      "        [ 27,  38,  39],\n",
      "        ...,\n",
      "        [ 54,  58,  60],\n",
      "        [ 52,  56,  58],\n",
      "        [ 35,  39,  41]],\n",
      "\n",
      "       [[ 23,  34,  35],\n",
      "        [ 26,  37,  38],\n",
      "        [ 29,  40,  41],\n",
      "        ...,\n",
      "        [ 39,  43,  45],\n",
      "        [ 43,  47,  49],\n",
      "        [ 29,  33,  35]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.5020370483398438, 'inference': 39.032936096191406, 'postprocess': 0.5004405975341797}\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 41.3ms\n",
      "Speed: 1.0ms preprocess, 41.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 84, 114, 100],\n",
      "        [ 71, 101,  87],\n",
      "        [ 82, 109,  96],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 70, 100,  86],\n",
      "        [ 96, 126, 112],\n",
      "        [107, 134, 121],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 53,  78,  65],\n",
      "        [ 76, 101,  88],\n",
      "        [ 92, 112, 100],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 28,  39,  40],\n",
      "        [ 26,  37,  38],\n",
      "        [ 23,  34,  35],\n",
      "        ...,\n",
      "        [ 61,  65,  67],\n",
      "        [ 55,  59,  61],\n",
      "        [ 41,  45,  47]],\n",
      "\n",
      "       [[ 25,  36,  37],\n",
      "        [ 26,  37,  38],\n",
      "        [ 27,  38,  39],\n",
      "        ...,\n",
      "        [ 54,  58,  60],\n",
      "        [ 52,  56,  58],\n",
      "        [ 35,  39,  41]],\n",
      "\n",
      "       [[ 23,  34,  35],\n",
      "        [ 26,  37,  38],\n",
      "        [ 29,  40,  41],\n",
      "        ...,\n",
      "        [ 39,  43,  45],\n",
      "        [ 43,  47,  49],\n",
      "        [ 29,  33,  35]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.001596450805664, 'inference': 41.29147529602051, 'postprocess': 0.7441043853759766}\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 0.9ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 84, 114, 100],\n",
      "        [ 71, 101,  87],\n",
      "        [ 82, 109,  96],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 70, 100,  86],\n",
      "        [ 96, 126, 112],\n",
      "        [107, 134, 121],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 53,  78,  65],\n",
      "        [ 76, 101,  88],\n",
      "        [ 92, 112, 100],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 28,  39,  40],\n",
      "        [ 26,  37,  38],\n",
      "        [ 23,  34,  35],\n",
      "        ...,\n",
      "        [ 61,  65,  67],\n",
      "        [ 55,  59,  61],\n",
      "        [ 41,  45,  47]],\n",
      "\n",
      "       [[ 25,  36,  37],\n",
      "        [ 26,  37,  38],\n",
      "        [ 27,  38,  39],\n",
      "        ...,\n",
      "        [ 54,  58,  60],\n",
      "        [ 52,  56,  58],\n",
      "        [ 35,  39,  41]],\n",
      "\n",
      "       [[ 23,  34,  35],\n",
      "        [ 26,  37,  38],\n",
      "        [ 29,  40,  41],\n",
      "        ...,\n",
      "        [ 39,  43,  45],\n",
      "        [ 43,  47,  49],\n",
      "        [ 29,  33,  35]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 0.8666515350341797, 'inference': 38.03229331970215, 'postprocess': 1.0006427764892578}\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.5ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 84, 114, 100],\n",
      "        [ 71, 101,  87],\n",
      "        [ 82, 109,  96],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 70, 100,  86],\n",
      "        [ 96, 126, 112],\n",
      "        [107, 134, 121],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 53,  78,  65],\n",
      "        [ 76, 101,  88],\n",
      "        [ 92, 112, 100],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 28,  39,  40],\n",
      "        [ 26,  37,  38],\n",
      "        [ 23,  34,  35],\n",
      "        ...,\n",
      "        [ 61,  65,  67],\n",
      "        [ 55,  59,  61],\n",
      "        [ 41,  45,  47]],\n",
      "\n",
      "       [[ 25,  36,  37],\n",
      "        [ 26,  37,  38],\n",
      "        [ 27,  38,  39],\n",
      "        ...,\n",
      "        [ 54,  58,  60],\n",
      "        [ 52,  56,  58],\n",
      "        [ 35,  39,  41]],\n",
      "\n",
      "       [[ 23,  34,  35],\n",
      "        [ 26,  37,  38],\n",
      "        [ 29,  40,  41],\n",
      "        ...,\n",
      "        [ 39,  43,  45],\n",
      "        [ 43,  47,  49],\n",
      "        [ 29,  33,  35]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.501321792602539, 'inference': 39.03341293334961, 'postprocess': 0.5006790161132812}\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 84, 114, 100],\n",
      "        [ 71, 101,  87],\n",
      "        [ 82, 109,  96],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 70, 100,  86],\n",
      "        [ 96, 126, 112],\n",
      "        [107, 134, 121],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 53,  78,  65],\n",
      "        [ 76, 101,  88],\n",
      "        [ 92, 112, 100],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 28,  39,  40],\n",
      "        [ 26,  37,  38],\n",
      "        [ 23,  34,  35],\n",
      "        ...,\n",
      "        [ 61,  65,  67],\n",
      "        [ 55,  59,  61],\n",
      "        [ 41,  45,  47]],\n",
      "\n",
      "       [[ 25,  36,  37],\n",
      "        [ 26,  37,  38],\n",
      "        [ 27,  38,  39],\n",
      "        ...,\n",
      "        [ 54,  58,  60],\n",
      "        [ 52,  56,  58],\n",
      "        [ 35,  39,  41]],\n",
      "\n",
      "       [[ 23,  34,  35],\n",
      "        [ 26,  37,  38],\n",
      "        [ 29,  40,  41],\n",
      "        ...,\n",
      "        [ 39,  43,  45],\n",
      "        [ 43,  47,  49],\n",
      "        [ 29,  33,  35]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.0006427764892578, 'inference': 39.534807205200195, 'postprocess': 0.9999275207519531}\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 84, 114, 100],\n",
      "        [ 71, 101,  87],\n",
      "        [ 82, 109,  96],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 70, 100,  86],\n",
      "        [ 96, 126, 112],\n",
      "        [107, 134, 121],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[ 53,  78,  65],\n",
      "        [ 76, 101,  88],\n",
      "        [ 92, 112, 100],\n",
      "        ...,\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 28,  39,  40],\n",
      "        [ 26,  37,  38],\n",
      "        [ 23,  34,  35],\n",
      "        ...,\n",
      "        [ 61,  65,  67],\n",
      "        [ 55,  59,  61],\n",
      "        [ 41,  45,  47]],\n",
      "\n",
      "       [[ 25,  36,  37],\n",
      "        [ 26,  37,  38],\n",
      "        [ 27,  38,  39],\n",
      "        ...,\n",
      "        [ 54,  58,  60],\n",
      "        [ 52,  56,  58],\n",
      "        [ 35,  39,  41]],\n",
      "\n",
      "       [[ 23,  34,  35],\n",
      "        [ 26,  37,  38],\n",
      "        [ 29,  40,  41],\n",
      "        ...,\n",
      "        [ 39,  43,  45],\n",
      "        [ 43,  47,  49],\n",
      "        [ 29,  33,  35]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 1.001119613647461, 'inference': 42.035579681396484, 'postprocess': 1.0006427764892578}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Carga del modelo, descarga en disco si no está presente en la carpeta\n",
    "model = YOLO('yolo11n.pt') #Contenedores\n",
    "\n",
    "# Etiqueta de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\"]\n",
    "\n",
    "\n",
    "# Captura desde la webcam\n",
    "filename = \"TGC23_PdH_C0056cut.mp4\"\n",
    "vid = cv2.VideoCapture(filename)\n",
    "track_history = defaultdict(lambda: [])\n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # si hay imagen válida\n",
    "    if ret:  \n",
    "        # Seguimiento, con persistencia entre fotogramas\n",
    "        results = model.track(img, persist=True, classes = [0,1,2])\n",
    "\n",
    "        if 1:\n",
    "            if results is not None:\n",
    "                print(results[0])\n",
    "                boxes = results[0].boxes.xywh.cpu()\n",
    "                if results[0].boxes.id is not None:\n",
    "                    track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "                else:\n",
    "                    track_ids = []\n",
    "                annotated_frame = results[0].plot()\n",
    "                for box, track_id in zip(boxes, track_ids):\n",
    "                    x, y, w, h = box\n",
    "                    track = track_history[track_id]\n",
    "                    track.append((float(x), float(y)))\n",
    "                    if len(track) > 30:\n",
    "                        track.pop(0)\n",
    "                    points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "                    cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
    "                cv2.imshow(\"YOLO11 Tracking\", annotated_frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                    break\n",
    "        \n",
    "\n",
    "        \n",
    "        # Para cada detección\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "\n",
    "                #Etiqueta de seguimiento\n",
    "                if box.id is not None:\n",
    "                    track_id = str(int(box.id[0].tolist()))\n",
    "                else:\n",
    "                    track_id = ''\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confianza --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Clase -->\", classNames[cls])\n",
    "\n",
    "                # Convierte identificador numérico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255*2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255*2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                # Dibuja el contenedor y clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, track_id + ' ' + classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', img)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 49.5ms\n",
      "Speed: 3.0ms preprocess, 49.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 47.5ms\n",
      "Speed: 1.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 41.5ms\n",
      "Speed: 1.4ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 40.5ms\n",
      "Speed: 1.5ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 5 persons, 39.5ms\n",
      "Speed: 1.5ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 5 persons, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 39.5ms\n",
      "Speed: 1.5ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 4 persons, 39.0ms\n",
      "Speed: 1.5ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.5ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Speed: 1.5ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.5ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.5ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.6ms\n",
      "Speed: 1.0ms preprocess, 38.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 57.0ms\n",
      "Speed: 1.0ms preprocess, 57.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.5ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.5ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.5ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.5ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.5ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.5ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.8ms\n",
      "Speed: 1.0ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.24\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.5ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.5ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.5ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.5ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.19\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.25\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.24\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.25\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.2ms\n",
      "Speed: 1.0ms preprocess, 37.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.5ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.5ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.5ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.5ms\n",
      "Speed: 2.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.5ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.5ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.5ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.5ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.5ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 0.5ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.5ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.5ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.5ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 42.0ms\n",
      "Speed: 2.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.5ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 36.5ms\n",
      "Speed: 0.5ms preprocess, 36.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 34.0ms\n",
      "Speed: 1.0ms preprocess, 34.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.5ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.5ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.2ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 51.0ms\n",
      "Speed: 2.0ms preprocess, 51.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.5ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.5ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.8ms\n",
      "Speed: 1.0ms preprocess, 37.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.5ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.5ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.5ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 36.0ms\n",
      "Speed: 1.5ms preprocess, 36.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.5ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 42.0ms\n",
      "Speed: 1.5ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.5ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 36.5ms\n",
      "Speed: 1.5ms preprocess, 36.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 38.5ms\n",
      "Speed: 1.5ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.5ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 0.5ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.5ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 38.0ms\n",
      "Speed: 1.5ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 42.5ms\n",
      "Speed: 17.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 42.5ms\n",
      "Speed: 1.5ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 38.4ms\n",
      "Speed: 1.1ms preprocess, 38.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 37.0ms\n",
      "Speed: 1.5ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.7\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.77\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.8\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.77\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Confianza ---> 0.82\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Confianza ---> 0.87\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Confianza ---> 0.85\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Confianza ---> 0.83\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 59.1ms\n",
      "Speed: 1.5ms preprocess, 59.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.81\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.82\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.83\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> bus\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Confianza ---> 0.89\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> bus\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> bus\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.77\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.88\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.88\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.91\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.77\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 38.0ms\n",
      "Speed: 1.5ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 38.0ms\n",
      "Speed: 1.5ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.22\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 1 bicycle, 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.36\n",
      "Clase --> car\n",
      "\n",
      "0: 384x640 2 persons, 36.5ms\n",
      "Speed: 1.5ms preprocess, 36.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 38.5ms\n",
      "Speed: 2.5ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> car\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 38.2ms\n",
      "Speed: 1.5ms preprocess, 38.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.7ms\n",
      "Speed: 1.0ms preprocess, 38.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Speed: 1.5ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.5ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 2 persons, 40.5ms\n",
      "Speed: 1.5ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "# Carga del modelo YOLO\n",
    "model = YOLO('yolo11n.pt')  # Contenedores\n",
    "\n",
    "# Etiqueta de las distintas clases\n",
    "classNames = [\"person\", \"car\", \"motorbike\", \"bus\"]\n",
    "\n",
    "# Captura desde el archivo de video\n",
    "filename = \"TGC23_PdH_C0056cut.mp4\"\n",
    "vid = cv2.VideoCapture(filename)\n",
    "\n",
    "# Obtenemos las propiedades del video original (ancho, alto, FPS)\n",
    "frame_width = int(vid.get(3))\n",
    "frame_height = int(vid.get(4))\n",
    "fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Inicializamos el VideoWriter para guardar el video anotado\n",
    "output_filename = 'video_anotado_solo_deteccion.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codificador de video\n",
    "out = cv2.VideoWriter(output_filename, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "track_history = defaultdict(lambda: [])\n",
    "\n",
    "while True:\n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "\n",
    "    # Si hay imagen válida\n",
    "    if ret:\n",
    "        # Seguimiento con persistencia entre fotogramas\n",
    "        results = model.track(img, persist=True, classes=[0,1,2,3])\n",
    "\n",
    "        if results is not None:\n",
    "            # Creamos una imagen en negro del mismo tamaño que el fotograma original\n",
    "            img_detections = np.zeros_like(img)\n",
    "\n",
    "            # Procesamos cada detección\n",
    "            for r in results:\n",
    "                boxes = r.boxes\n",
    "\n",
    "                for box in boxes:\n",
    "                    # Contenedor de cada detección\n",
    "                    x1, y1, x2, y2 = box.xyxy[0]\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                    # Recortar el área detectada en el fotograma original\n",
    "                    detection_crop = img[y1:y2, x1:x2]\n",
    "\n",
    "                    # Pegar el área recortada en la imagen en negro\n",
    "                    img_detections[y1:y2, x1:x2] = detection_crop\n",
    "\n",
    "                    # Dibuja un recuadro y pone la etiqueta en la imagen de detecciones\n",
    "                    if box.id is not None:\n",
    "                        track_id = str(int(box.id[0].tolist()))\n",
    "                    else:\n",
    "                        track_id = ''\n",
    "\n",
    "                    # Confianza\n",
    "                    confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "                    print(\"Confianza --->\", confidence)\n",
    "\n",
    "                    # Clase\n",
    "                    cls = int(box.cls[0])\n",
    "                    print(\"Clase -->\", classNames[cls])\n",
    "\n",
    "                    # Dibuja el contenedor y clase en la imagen de detección\n",
    "                    cv2.rectangle(img_detections, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "                    cv2.putText(img_detections, track_id + ' ' + classNames[cls], (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            # Guardar el fotograma procesado en el archivo de video\n",
    "            out.write(img_detections)\n",
    "            cv2.imshow(\"Detección YOLO\", img_detections)\n",
    "\n",
    "            # Detener si se presiona la tecla \"q\"\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "    # Detenemos el proceso si se presiona ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "\n",
    "# Libera los recursos\n",
    "vid.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.24 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.23  Python-3.9.20 torch-2.5.0+cpu \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: 0\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolov8n.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# También puedes usar 'yolov8s.pt' para un modelo más grande\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo con tu dataset personalizado\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlicense.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# El archivo de configuración YAML\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ajusta el número de épocas según sea necesario\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m433\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Tamaño de las imágenes (puedes ajustarlo)\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Tamaño del batch\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Para entrenar con GPU, usa '0'. Para CPU, usa 'cpu'\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\ultralytics\\engine\\model.py:796\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    794\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[1;32m--> 796\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\ultralytics\\engine\\trainer.py:103\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m get_cfg(cfg, overrides)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_resume(overrides)\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[43mselect_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\ultralytics\\utils\\torch_utils.py:192\u001b[0m, in \u001b[0;36mselect_device\u001b[1;34m(device, batch, newline, verbose)\u001b[0m\n\u001b[0;32m    185\u001b[0m         LOGGER\u001b[38;5;241m.\u001b[39minfo(s)\n\u001b[0;32m    186\u001b[0m         install \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    187\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA devices are seen by torch.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    190\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m         )\n\u001b[1;32m--> 192\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    193\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requested.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    194\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=cpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or pass valid CUDA device(s) if available,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m i.e. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=0\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=0,1,2,3\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for Multi-GPU.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    196\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtorch.cuda.is_available(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    197\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtorch.cuda.device_count(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mos.environ[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvisible\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    200\u001b[0m         )\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cpu \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mps \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():  \u001b[38;5;66;03m# prefer GPU if available\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     devices \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# i.e. \"0,1\" -> [\"0\", \"1\"]\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: 0\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Cargar el modelo YOLOv8 (puedes usar uno preentrenado)\n",
    "model = YOLO('yolov8n.pt')  # También puedes usar 'yolov8s.pt' para un modelo más grande\n",
    "\n",
    "# Entrenar el modelo con tu dataset personalizado\n",
    "model.train(\n",
    "    data='license.yaml',  # El archivo de configuración YAML\n",
    "    epochs=50,  # Ajusta el número de épocas según sea necesario\n",
    "    imgsz=433,  # Tamaño de las imágenes (puedes ajustarlo)\n",
    "    batch=16,   # Tamaño del batch\n",
    "    device='cpu'    # Para entrenar con GPU, usa '0'. Para CPU, usa 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intregración con seguimiento (tracking)\n",
    "!!!!!!!!!Nota: he tenido que bajar a la versión de python 3.9.5 e instalar lap con pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('yolo11n.pt') #Contenedores\n",
    "#model = YOLO('yolov11n-seg.pt') #Máscaras\n",
    "#model = YOLO('yolo11n-pose.pt')  #Pose\n",
    "\n",
    "#Para un vídeo \n",
    "filename = \"TGC23_PdH_C0056cut.mp4\"\n",
    "results = model.track(source=filename, show=True)  # BoT-SORT tracker (por defecto)\n",
    "#results = model.track(source=filename, show=True, tracker=\"bytetrack.yaml\")  # ByteTrack tracker\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento de caracteres tras instalar pytesseract y tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tesseract\n",
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "\n",
    "# Previamente debes descargar los ejecutables\n",
    "# Si la ruta de Tesseract no está en el PATH, ruta al ejecutable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "\n",
    "# Lenguajes disponibles\n",
    "print(pytesseract.get_languages(config=''))\n",
    "\n",
    "#Cargo imagen y ocnvierto a RGB\n",
    "img = cv2.imread('ocr_test.tif') \n",
    "\n",
    "if img is not None:\n",
    "    #Convierte a RGB antes de procesar\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #Texto localizado\n",
    "    print(pytesseract.image_to_string(img))\n",
    "\n",
    "    #Texto y localización en imagen de cada palabra\n",
    "    d = pytesseract.image_to_data(img_rgb, output_type=Output.DICT)\n",
    "\n",
    "    n_boxes = len(d['text'])\n",
    "    for i in range(n_boxes):\n",
    "        #Nivel de confianza\n",
    "        if int(d['conf'][i]) > 60:\n",
    "            text = d['text'][i]\n",
    "            conf = d['conf'][i]\n",
    "            (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            print(f'Texto: {text} ({conf:.2f}%)\\nContenedor: {x,y,x+w,y+h}')\n",
    "\n",
    "    cv2.imshow('img', img_rgb)\n",
    "    cv2.waitKey(-1)\n",
    "\n",
    "   \n",
    "\n",
    "else:\n",
    "    print('Error de imagen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento de caracteres tras instalar easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "\n",
    "#Carga del modelo de lengua\n",
    "reader = easyocr.Reader(['es']) \n",
    "\n",
    "#Reconocimiento de una imagen\n",
    "res = reader.readtext('ocr_test.tif')\n",
    "\n",
    "for (bbox, text, prob) in res:\n",
    "    # Coordenadas en orden \n",
    "    (top_left, top_right, bottom_right, bottom_left) = bbox\n",
    "    print(f'\\nTexto: {text}\\nProbabilidad: {prob:.2f}\\nContenedor: {tuple(map(int, top_left)),tuple(map(int, bottom_right))}')\n",
    "\n",
    "\n",
    "#Con restricción de caracteres reconocibles\n",
    "#result = reader.readtext('toy.tif', allowlist ='0123456789')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
